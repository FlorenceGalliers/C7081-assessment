data = data,
nvmax = 10,
method = "backward")
bwd.summary <- summary(model.bwd)
which.min(fwd.summary$rss) # best model 10
which.min(fwd.summary$cp) # best model 4
which.min(fwd.summary$bic) # best model 3
which.max(fwd.summary$adjr2) # best model 4
par(mfrow=c(2,2)) # change output to 2 x 2
plot(fwd.summary$rss,
xlab = "Number of Variables",
ylab = "RSS",
type = "l")
points(10, fwd.summary$rss[10],
col = "red",
cex = 2,
pch = 20)
plot(fwd.summary$cp,
xlab = "Number of Variables",
ylab = "Cp",
type = "l")
points(4, fwd.summary$cp[4],
col = "red",
cex = 2,
pch = 20)
plot(fwd.summary$bic,
xlab = "Number of Variables",
ylab = "BIC",
type = "l")
points(3, fwd.summary$bic[3],
col = "red",
cex = 2,
pch = 20)
plot(fwd.summary$adjr2,
xlab = "Number of Variables",
ylab = "Adjusted R^2",
type = "l")
points(4, fwd.summary$adjr2[4],
col = "red",
cex = 2,
pch = 20)
which.min(bwd.summary$rss) # best model 10
pairs.panels(data2, col="red")
library(psych)
pairs.panels(data2, col="red")
# set working directory
setwd("~/Google Drive/Harper/1 Statistical Analysis for Data Science/Asssesment/github-C7081/C7081-assessment")
# read in data
library(openxlsx)
data2 <- read.xlsx("housing_data_assessment.xlsx")
# remove outliers
outliers <- c(100, 2387, 2921)
data2 <- data2[-outliers, ]
# data preparation
data2 <- data2[ ,-11] # remove column 11 "city" as character variable
data2$condition <- as.factor(data2$condition) # make condition variable a factor
data2$renovated <- as.factor(data2$renovated) # make renovated variable a factor
data2$basement <- as.factor(data2$basement) # make basement variable a factor
# look if any values have price= 0, assign them to variable
zero_values <- which(data2$price == 0)
# remove these from the data set as house price cannot = 0
data2 <- data2[-zero_values, ]
library(psych)
pairs.panels(data2, col="red")
library(ggplot2)
install.packages("ggplot2")
library(ggplot2)
cormat <- cor(data2)
cor(data2)
?cor.plot
cor(data2)
cor(data2, use="pairwise.complete.obs")
corr_variables <- c(data2$price, data2$bed, data2$bath, data2$sqft_living,
data2$sqft_total, data2$floors, data2$yr_built)
corr_variables <- data.frame(data2$price, data2$bed, data2$bath, data2$sqft_living,
data2$sqft_total, data2$floors, data2$yr_built)
cor(corr_variables)
cor_mat <- cor(corr_variables)
library(ggplot2)
ggcorrplot(cor_mat)
install.packages("ggcorrplot")
library(ggcorrplot)
ggcorrplot(cor_mat)
ggcorrplot(cor_mat, method = "circle")
ggcorrplot(cor_mat, method = "circle", type = "lower")
ggcorrplot(cor_mat,
method = "circle",
type = "lower",
lab = TRUE)
p_mat <- cor_pmat(corr_variables)
ggcorrplot(cor_mat,
method = "circle",
type = "lower",
p.mat = p+mat)
ggcorrplot(cor_mat,
method = "circle",
type = "lower",
p.mat = p_mat)
ggcorrplot(cor_mat,
method = "circle",
type = "lower",
lab = T)
ggcorrplot(cor_mat,
method = "circle",
type = "lower",
p.mat = p_mat)
ggcorrplot(cor_mat,
method = "circle",
type = "lower",
p.mat = p_mat,
lab = T)
ggcorrplot(cor_mat,
method = "circle",
type = "lower",
p.mat = p_mat,
lab = T, lab_size = 0.5)
ggcorrplot(cor_mat,
method = "circle",
type = "lower",
p.mat = p_mat,
lab = T, lab_size = 5)
ggcorrplot(cor_mat,
method = "circle",
type = "lower",
p.mat = p_mat,
lab = T, lab_size = 3)
ggcorrplot(cor_mat,
method = "circle",
type = "lower",
p.mat = p_mat,
lab = T, lab_size = 2.5)
ggcorrplot(cor_mat,
method = "circle",
type = "lower",
p.mat = p_mat,
lab = T, lab_size = 2.5, label_alpha = T)
# set working directory
setwd("~/Google Drive/Harper/1 Statistical Analysis for Data Science/Asssesment/github-C7081/C7081-assessment")
# read in data
library(openxlsx)
data2 <- read.xlsx("housing_data_assessment.xlsx")
# remove outliers
outliers <- c(100, 2387, 2921)
data2 <- data2[-outliers, ]
# data preparation
data2 <- data2[ ,-11] # remove column 11 "city" as character variable
data2$condition <- as.factor(data2$condition) # make condition variable a factor
data2$renovated <- as.factor(data2$renovated) # make renovated variable a factor
data2$basement <- as.factor(data2$basement) # make basement variable a factor
# look if any values have price= 0, assign them to variable
zero_values <- which(data2$price == 0)
# remove these from the data set as house price cannot = 0
data2 <- data2[-zero_values, ]
corr_variables <- data.frame(data2$price, data2$bed, data2$bath, data2$sqft_living,
data2$sqft_total, data2$floors, data2$yr_built)
cor_mat <- cor(corr_variables)
p_mat <- cor_pmat(corr_variables)
ggcorrplot(cor_mat,
method = "circle",
type = "lower",
p.mat = p_mat,
lab = T, lab_size = 2.5)
# split into training and test data sets
set.seed(1)
train <- sample(c(TRUE, FALSE), nrow(data2), rep = TRUE)
test <- (!train)
training_set <- data2[train,]
testing_set <- data2[test,]
# fit linear model using least squares on training data
lm_model <- lm(price ~ .,
data = training_set)
# make predictions on test set
lm_pred <- predict(lm_model, testing_set)
# calculate MSE
mean((testing_set[, "price"] - lm_pred)^2)
summary(lm_model)
# Diagnostic plots of the linear regression model
par(mfrow=c(2,2))
plot(lm_model)
library(glmnet)
set.seed(1)
x <- model.matrix(price ~ ., data = data2)[,-1]
y <- data2$price
cv.ridge <- cv.glmnet(x[train,], y[train], alpha = 0)
plot(cv.ridge)
best.lambda <- cv.ridge$lambda.min
best.lambda
ridge.mod <- glmnet(x[train, ], y[train], alpha = 0)
ridge.pred <- predict(ridge.mod, s = best.lambda,
newx = x[test,])
mean((ridge.pred - y[test])^2)
lasso.mod <- glmnet(x[train,],
y[train],
alpha = 1)
plot(lasso.mod)
set.seed(1)
cv.lasso <- cv.glmnet(x[train,],
y[train],
alpha = 1)
plot(cv.lasso)
best.lamb <- cv.lasso$lambda.min
lasso.pred <- predict(lasso.mod, s = best.lamb,
newx = x[test,])
mean((lasso.pred - y[test])^2)
out <- glmnet(x, y, alpha = 1)
lasso.coef <- predict(out, type = "coefficients",
s = best.lamb)
lasso.coef
lasso.coef[lasso.coef!=0]
library(pls)
set.seed(2)
pcr.fit <- pcr(price ~ .,
data = house.train,
scale = TRUE,
validation = "CV")
summary(pcr.fit)
validationplot(pcr.fit, val.type = "MSEP")
names(pcr.fit)
pcr.pred <- predict(pcr.fit, x[test,], ncomp = 9)
mean((pcr.pred - y[test])^2)
pls.fit <- plsr(price ~ .,
data = house.train,
scale = TRUE,
validation = "CV")
summary(pls.fit)
validationplot(pls.fit, val.type = "MSEP")
pls.pred <- predict(pls.fit, x[test,], ncomp = 3)
mean((pls.pred - y[test])^2)
pls.fit <- plsr(price ~ ., data = data2, scale = TRUE, ncomp = 3)
summary(pls.fit)
library(leaps)
regsub.fit <- regsubsets(price ~ .,
data = data2[train, ],
nvmax = 9)
test.matrix <- model.matrix(price ~ .,
data = data2[test,])
val.errors <- rep(NA, 9)
for(i in 1:9) {
coefi <- coef(regsub.fit, id = i)
pred <- test.matrix[ ,names(coefi)]%*%coefi
val.errors[i]=mean((data2$price[test]-pred)^2)
}
val.errors
which.min(val.errors)
coef(regsub.fit, 7)
predict.regsubsets <- function(object, newdata, id, ...){
form <- as.formula(object$call[[2]])
mat <- model.matrix(form, newdata)
coefi <- coef(object, id=id)
xvars <- names(coefi)
mat[, xvars]%*%coefi
}
regfit.best <- regsubsets(price ~ .,
data = data2,
nvmax = 9)
coef(regfit.best, 7)
reg.summary <- summary(regfit.best)
k <- 10
set.seed(1)
folds <- sample(1:k, nrow(data2), replace = TRUE)
cv.errors <- matrix(NA, k, 9, dimnames = list(NULL, paste(1:9)))
for(j in 1:k){
best.fit <- regsubsets(price ~ .,
data = data2[folds!=j,],
nvmax = 9)
for (i in 1:9) {
pred <- predict(best.fit, data2[folds==j,], id=i)
cv.errors[j, i]=mean((data2$price[folds==j]-pred)^2)
}
}
mean.cv.errors <- apply(cv.errors, 2, mean)
mean.cv.errors
plot(mean.cv.errors, type = "b")
which.max(reg.summary$adjr2)
which.min(reg.summary$cp)
which.min(reg.summary$bic)
par(mfrow=c(2,2))
plot(reg.summary$rss,
xlab="Number of Variables",
ylab="RSS",
type = "l")
plot(reg.summary$adjr2,
xlab = "Number of Variables",
ylab = "Adjusted RSq",
type = "l")
points(7, reg.summary$adjr2[7], col="red", cex=2, pch=20)
plot(reg.summary$cp,
xlab = "Number of Variables",
ylab = "Cp",
type = "l")
points(7, reg.summary$cp[7], # this is giving the coordinates of the point
# on the graph to plot, 10 on the x axis and the 10th value of the cp on
# y axis
col = "red",
cex = 2,
pch = 20)
plot(reg.summary$bic,
xlab = "Number of Variables",
ylab = "BIC",
type = "l")
points(5, reg.summary$bic[5],
col = "red",
cex = 2,
pch = 20)
regfit.fwd <- regsubsets(price ~ .,
data = data2,
nvmax = 9,
method = "forward")
summary(regfit.fwd)
regfit.bwd <- regsubsets(price ~ .,
data = data2,
nvmax = 9,
method = "backward")
summary(regfit.bwd)
poly_10 <- lm(price ~ poly(sqft_living, degree = 10),
data = data2)
coef(summary(poly_10))
summary(lm(formula = price ~ sqft_living + yr_built * bed + yr_built:condition),
data = data2)
# Set WD, Read in Data
setwd("~/Google Drive/Harper/1 Statistical Analysis for Data Science/Asssesment/github-C7081/C7081-assessment")
library(openxlsx)
data2 <- read.xlsx("housing_data_assessment.xlsx")
# remove outliers
outliers <- c(100, 2387, 2921)
data2 <- data2[-outliers, ]
# data preparation
data2 <- data2[ ,-11] # remove column 11 "city" as character variable
data2$condition <- as.factor(data2$condition) # make condition variable a factor
data2$renovated <- as.factor(data2$renovated) # make renovated variable a factor
data2$basement <- as.factor(data2$basement) # make basement variable a factor
# Split into training and test data sets
set.seed(1)
train <- sample(c(TRUE, FALSE), nrow(data2), rep = TRUE)
test <- (!train)
house.train <- data2[train,]
house.test <- data2[test,]
# Regression Tree
tree_house <- tree(price ~ .,
data = house.train)
summary(tree_house)
plot(tree_house)
text(tree_house, pretty = 0, cex = 0.8)
tree_house
cv_tree <- cv.tree(tree_house)
plot(cv_tree$size, cv_tree$dev, type = "b")
prunedtree <- prune.tree(tree_house, best = 8)
plot(prunedtree)
text(prunedtree, pretty = 0)
mean(data2$price)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
install.packages("keras")
library(keras)
library(keras)
mnist <- dataset_mnist()
library(tensorflow)
train_images <- mnist$train$x
train_labels <- mnist$train$y
test_images <- mnist$test$x
test_labels <- mnist$test$y
library(keras)
mnist <- dataset_mnist()
train_images <- mnist$train$x
train_labels <- mnist$train$y
test_images <- mnist$test$x
test_labels <- mnist$test$y
str(train_images)
str(train_labels)
str(test_images)
str(test_labels)
network <- keras_model_sequential() %>%
layer_dense(units = 512, activation = "relu", input_shape = c(28 * 28)) %>%
layer_dense(units = 10, activation = "softmax")
library(tensorflow)
network <- keras_model_sequential() %>%
layer_dense(units = 512, activation = "relu", input_shape = c(28 * 28)) %>%
layer_dense(units = 10, activation = "softmax")
network %>% compile(
optimizer = "rmsprop",
loss = "categorical_crossentropy",
metrics = c("accuracy")
)
train_images <- array_reshape(train_images, c(60000, 28 * 28))
train_images <- train_images / 255
test_images <- array_reshape(test_images, c(10000, 28 * 28))
test_images <- test_images / 255
train_labels <- to_categorical(train_labels)
test_labels <- to_categorical(test_labels)
network %>% fit(train_images, train_labels, epochs = 5, batch_size = 128)
metrics <- network %>% evaluate(test_images, test_labels, verbose = 0)
metrics
my_vector <- c(11.3, 11.2, 10.4, 10.4, 8.7, 10.8, 10.5, 10.3, 9.7, 11.2)
# Return all values
my_vector   # Typical way
my_vector[] # # Square brackets with blank index implies all index values
my_vector[1:10] # All index value explicitly
# Return the first 3 values
1:3 # Reminder of the function of the colon operator ":"
my_vector[1:3] # Notice consecutive indices can use the ":" operator
# Return 5th and 9th values
my_vector[c(5,9)] # Notice we have to place non-consecutive index values in the c() function
my_matrix <- matrix(data = c(2,3,4,5,6,6,6,6),
nrow = 2, byrow = T)
my_matrix # notice how the arguments arranged the data
matrix(data=c(2,3,4,5,6,6,6,6), nrow=4, byrow=F)
# "Slicing" out a row or column
my_matrix[1,  ] # Slice out row 1
my_matric[ , 3] # Slice out column 3
# Matrix columns and rows often have names
names(my_matrix) # No names yet
nrow(my_matrix) # Returns number of rows (useful for large matrices)
rownames(my_matrix) # No row names; 2 rows, need two names
rownames(my_matrix) <- c("dogs", "cats")
my_matrix # Now the rows have names!
rownames(my_matrix) # Get them this way too!
ncol(my_matrix)
colnames(my_matrix) <- c("a", "b", "c", "d")
my_matrix
# You can also slice out matrix portions by name
my_matrix["dogs", c("b", "d")]
# Finally, functions act on values, not index value
mean(my_matrix["dogs", c("b", "d")])
help(runif)
help(round)
# Try it to see what it does...
my_vec <- round(runif(n = 27, min = 0, max = 100), 0)
my_vec # See what I did there?
length(my_vec) # Just checking
my_array <- array(data = my_vec,
dim = c(3, 3, 3))
my_array
my_array[, ,c(1,3)]
# Try this
help(which) # Notice how the x argument is required to be a LOGICAL vector?
# Make a NUMERIC vector
vector_a <- c(3, 4, 5, 4, 3, 4, 5, 6, 6, 7)
# Use a boolean phrase to ask which elements of vector_a are greater than 5
vector_a > 5 # Interesting... it is a LOGICAL vector!
# The which function will return the index values of TRUE values
# In other words, WHICH values in vector_a are greater than 5?
which(vector_a > 5)
# What VALUES in vector_a are > 5?
vector_a[which(vector_a > 5)]
# This also works on vectors of other types
# Consider a character vector
char_vec <- c("wheat", "maize", "wheat", "maize", "wheat", "wheat")
# Which elements are equivalent to "wheat"?
char_vec == "wheat"
which(char_vec == "wheat")
char_vec[which(char_vec == "wheat")] # This works
char_vec[char_vec == "wheat"]        # Same output
char_vec[char_vec == "wheat"]
# Load the OrchardSpray data using the data() function
data(OrchardSprays) # Should see OrchardSprays <promise> in the Global Env.
# Look at the data head()
head(OrchardSprays) # First 6 rows
# Look at variable types with str()
help(str) # Good function to see info about data object
str(OrchardSprays)
# First let's just look at the data
# Don't worry too much about the code for these graphs if you have not encountered it before
boxplot(decrease ~ treatment, data = OrchardSprays,
main = "The pattern fits the prediction",
ylab = "Amount of sucrose consumed",
xlab = "Lime sulpher treatment amount in decreasing order (H = control)")
# This is the experimental design
# Latin Square is kind of like Sudoku
# No treatment can be in row or column more than once
plot(x = OrchardSprays$colpos,  # NB use of $ syntax to access data
y = OrchardSprays$rowpos,
pch = as.character(OrchardSprays$treatment),
xlim = c(0,9), ylim = c(0,9),
main = "The Latin Square design of treatments",
xlab = "\"Column\" position",
ylab = "\"Row\" position")
# 01 Boolean phrase
OrchardSprays$treatment # Just print variable to compare visually to boolean
OrchardSprays$treatment == "D" # logical vector - TRUE in "D" positions
# 02 which()
which(OrchardSprays$treatment == "D") # Index of TRUE values
my_selec1 <- which(OrchardSprays$treatment == "D") # Place index in a variable
my_selec1 # Just checking
# 03 Exploit [ , ] syntax with data frame object to slice out rows
OrchardSprays[my_selec1, ]
OrchardSprays$colpos #print variable to compare to boolean
OrchardSprays$colpos == "2" #logical vector, TRUE in "2" positions
which(OrchardSprays$colpos == "2") #Index of TRUE values
my_selec2 <- which(OrchardSprays$colpos == "2") #place index in variable
my_selec2
OrchardSprays[my_selec2, ]
# rowpos 4 and 6
OrchardSprays$rowpos == 4 # The 4s
OrchardSprays$rowpos == 6 # The 6s
OrchardSprays$rowpos == 4 | OrchardSprays$rowpos == 6 # All together
# now with which()
which(OrchardSprays$rowpos == 4) # The 4s
which(OrchardSprays$rowpos == 6) # The 6s
which(OrchardSprays$rowpos == 4 | OrchardSprays$rowpos == 6) # All together
# treatment A and H
which(OrchardSprays$treatment == "A" | OrchardSprays$treatment == "H") # All together
which((OrchardSprays$rowpos == 4 | OrchardSprays$rowpos == 6) &  # It works
(OrchardSprays$treatment == "A" | OrchardSprays$treatment == "H") )
my_selec3 <- which((OrchardSprays$rowpos == 4 | OrchardSprays$rowpos == 6) &
(OrchardSprays$treatment == "A" | OrchardSprays$treatment == "H") )
OrchardSprays[my_selec3, ] # Double check it works and is similar to expectation...
treatA <- which(OrchardSprays$treatment == "A")
treatH <- which(OrchardSprays$treatment == "H")
OrchardSprays[c(treatA, treatH), ]
mean(OrchardSprays$decrease[treatA])
mean(OrchardSprays$decrease[treatH])
(3+4+12+5+4+5+2+2)/8
(69+127+72+130+81+76+81+86)/8
